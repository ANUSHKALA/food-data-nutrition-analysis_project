# -*- coding: utf-8 -*-
"""CIS 545 Final Project Food Notebook - Yuxuan Gao, Raunaq Singh, Daniel Duan

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XWfAawaRL18eDgV9NCHDc2d-p3kG8ry0

# CIS 545 Final Project - Food Nutrition Analysis

#### **Yuxuan Gao, Raunaq Singh, Daniel Duan**

## Introduction

*NOTE: We originally planned to do a blog post as our deliverable, but we have instead done an annotated notebook.*

Welcome to our final project, where we conduct an analysis of food nutrition using the Open Food Facts dataset provided by Kaggle! This dataset contains nutrition facts about food products from all over the world. First, we'll spend some time cleaning up and reformatting the raw data while analyzing it for any interesting observations or correlations. Next, we'll focus on using and testing multiple models (Decision Tree, Logistic Regression, Linear Regression, Random Forest Regression) to see if we can accurately predict a product's nutrition score based on major ingredients in the product. We also will use computer vision to attempt to train a model to classify foods as "Very Healthy," "Moderately Healthy," "Moderately Unhealthy," or "Very Unhealthy" based off of their images. Lastly, we conduct a brief regression analysis on how much energy food items provide.

## Required Setup
In order to download the raw dataset from Kaggle you will need access to your Kaggle credentials (i.e. username and API Key). Here are the necessary steps to do so:
1. Create an account on [Kaggle](https://www.kaggle.com/).
2. Sign in to [Kaggle](https://kaggle.com), then click on your profile picture on the top right and select "My Account" from the menu.
3. Scroll down to the "API" section and click "Create New API Token". This will download a file `kaggle.json` with the following contents:
```
{"username":"YOUR_KAGGLE_USERNAME","key":"YOUR_KAGGLE_KEY"}
```
4. When you run `od.download` (In the **Library Setup** section of the notebook), you will be asked to enter your username & Kaggle API, which you can get from the file downloaded in step 3.

## Library Setup 
Run the following cells to import the necessary packages and load the raw dataset from Kaggle into a Pandas dataframe.
"""

!pip install opendatasets
!pip3 install --upgrade mxnet-cu101 gluoncv

import opendatasets as od
import pandas as pd
import numpy as np
import seaborn as sns
from scipy import stats
from string import ascii_letters
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
import sklearn as sklearn

# Download raw dataset from Kaggle
od.download("https://www.kaggle.com/openfoodfacts/world-food-facts")

"""Now let's populate our dataframe"""

# Load tsv file into dataframe food_df
food_df = pd.read_table("world-food-facts/en.openfoodfacts.org.products.tsv", error_bad_lines=False, lineterminator='\n')

"""Awesome! Let's see what `food_df` looks like. """

# See what the food_df looks like!
food_df.head(5)

"""## Data Wrangling and Cleaning
As you can see above, `food_df` is currently quite unorganized and presented in a form that is not very helpful for our purposes: there are many entires with `NaN` values in different varying columns, there are a lot of extraneous columns with few values that aren't `NaN`, some products belong to multiple countries, etc. etc. This section will focus on cleaning up `food_df` and making it more presentable.

First, we make sure to drop any duplicate values that may appear within the dataframe.
Then, we only keep the columns with sufficient data and that are important contributors to a food's overall nutrition. For example, we will keep `fat_100g`, `cholesterol_100g`, etc. We decided to drop columns like `folates_100g` that are sparsely filled and not extremely indicative of a product's nutrition score. We mainly chose this list of columns based off of our own intutition.
"""

# Remove duplicate values
food_df = food_df.drop_duplicates()

# Only Select columns with sufficient data and of great predictive value
food_df = food_df[["product_name", "countries_en", "image_url", "ingredients_text", "fat_100g", "cholesterol_100g", "carbohydrates_100g", "sugars_100g", "fiber_100g", "proteins_100g", "sodium_100g", "energy_100g", "nutrition-score-uk_100g"]].dropna()
food_df.head(5)

"""`food_df` already looks much cleaner! We now have a dataframe consisting of non-empty values of important ingredients. Let's check the datatype of each remaining column."""

# Check data types of the columns
food_df.dtypes

"""Next, notice how some products appear in multiple countries (i.e. in their `countries_en` column, their value is `United States, France, Germany`). Let's split up those products using the `explode` function. """

# split up proudcts that are sold in multiply countries
food_df["countries_en"]=food_df["countries_en"].str.split(",")
food_df = food_df.explode("countries_en").reset_index(drop=True)
food_df.head(5)

"""The dataframe looks clean and ready to use now!

## EDA
Now let's see if we can find any cool observations from the dataset using **exploratory data analysis**. 
Note that we describe and interpret any relevant findings **after** each code snippet.

First, let's compute some simple statistics between the numeric columns in `food_df`. These columns include `fat_100g`, `cholesterol_100g`, etc. etc.
"""

# Calculate the max, min, standard deviation, and mean of all the numeric columns
numeric_df = food_df.drop(columns=['product_name', 'countries_en', 'image_url', 'ingredients_text'])
maxes = numeric_df.max().tolist()
mins = numeric_df.min().tolist()
stds = numeric_df.std().tolist()
means = numeric_df.mean().tolist()

print(maxes)
print(mins)
print(stds)
print(means)

"""From this, we can see that the amount of certain ingredients can vary immensely among products. For example, the calculated standard deviation of `energy_100g` is `860`. Some food products provide so much more energy than others!

Next, let's get a visual representation of the most popular ingredients used in products through a Word Cloud.
"""

# Explode the ingreidents_text
copy_food_df = food_df.copy()
copy_food_df['ingredients_text'] = copy_food_df['ingredients_text'].str.split(',').tolist()
copy_food_df = copy_food_df.explode('ingredients_text')

# generate a Word Cloud based on the ingredients
ingredients_word_cloud = WordCloud().generate(' '.join(copy_food_df['ingredients_text']))
plt.imshow(ingredients_word_cloud)
plt.axis("off")
plt.show

"""From this, we can see that sugar and salt seem to be the most relevant ingredients in most products, which doesn't really come of as a surprise.

Now let's group the food products by country and visually represent each countries average nutrition score. To do this, we have to first split up foods that belong to mulitple countries using the `explode` function. Then, since some countries only have one or two food products associated with them, we should only consider countries that produce over three food products. 

***Note: The lower the nutrition score, the healthier the food is!***
"""

#split up foods with multiply countries
food_df["countries_en"]=food_df["countries_en"].str.split(",")
country_exploded_df = food_df.explode("countries_en").reset_index(drop=True)

#only consider countries with over 3 products in the dataframe
country_count_df = country_exploded_df.groupby(["countries_en"], as_index=False).count()[["countries_en", "product_name"]]
country_count_df = country_count_df[country_count_df["product_name"] > 3]

country_nutrition_df = country_exploded_df.groupby(["countries_en"], as_index=False).mean().round(2)[["countries_en", "nutrition-score-uk_100g"]]
country_nutrition_df = country_nutrition_df.merge(country_count_df[["countries_en"]], left_on=["countries_en"], right_on=["countries_en"])

#NOTE: lower nutrition-score -> healthier
country_nutrition_df.sort_values(["nutrition-score-uk_100g"], ascending=[False])

#Map Visualization
plot = sns.barplot(x="countries_en", y="nutrition-score-uk_100g", data=country_nutrition_df, order=country_nutrition_df.sort_values(["nutrition-score-uk_100g"], ascending=[True])["countries_en"])
plt.xticks(rotation=90)
plt.xlabel("Country")
plt.ylabel("Nutrition Score")
plt.title("Average Nutrition Score for Foods by Country")

"""Nice! Out of the countries that have more than 3 food products associated with them, our graph indicates that Switzerland produces the healthiest food items, while Tunisia products the least healthy food items.

Next let's plot a correlation heatmap to see just how closely certain ingredients are correlated with each other.
"""

# Plot correlation heatmap for all pairs of variables
sns.set(style = "white")
sns.set(rc={'figure.figsize':(9,6)})

corr = food_df.corr()

mask = np.zeros_like(corr, dtype=np.bool)
mask[np.triu_indices_from(mask)] = True

cmap = sns.diverging_palette(220, 10, as_cmap=True)

sns.heatmap(corr, mask=mask)

plt.title("Correlation Heatmap")
plt.show()

# Display correlation matrix
corr

"""From the Correlation Heatmap, visually we can see that `fat_100g` has significant correlation with `carbohydrates_100g` and `sugars_100g` is significantly correlated with `proteins_100g`. In order to address any possible issues with multicollinearity, in our `Modeling` section we'll be sure to use PCA beforehand.

Let's look a little more closely at how certain ingredients are correlated with a product's overall nutrition score. We'll primarily be focusing on the correlation between fat and nutrition score. Let's first run a linear regression analysis between `fat_100g` and `nutrition-score-uk_100g` and report the `R-squared` value.
"""

# Linear regression analysis of variables fat_100g and nutrition-score-uk_100g
sns.set(color_codes=True)
slope, intercept, r_value, p_value, std_err = stats.linregress(food_df['fat_100g'], food_df['nutrition-score-uk_100g'])
ax = sns.regplot(x="fat_100g", y="nutrition-score-uk_100g", data=food_df, line_kws={'color':'red'})
print("R-squared value on training set is:", round(pow(r_value, 2) * 100, 2), "%")

"""From this linear regression analysis we can see that the R-squared value is only 32.24%, which isn't very high. We can see visually however that there does appear to be a slight positive correlation between `fat_100g` and `nutrition-score-uk_100g`. Let's see if we can test the accuracy of our linear regression by analysing a plot of the residuals. """

# Plot residuals from the prediction
sns.residplot(x="fat_100g", y="nutrition-score-uk_100g", data=food_df, scatter_kws={"s": 80})

"""Hmmm... It seems that the points aren't very randomly disperesed around the horiziontal axis. Let's try our luck with a polynomial regression analysis between `fat_100g` and `nutrition-score-uk_100g`, and see if a polynomial regression model can be more accurate. """

# Polynomial regression analysis of variables fat_100g and nutrition-score-uk_100g
sns.set(color_codes=True)
ax = sns.regplot(x="fat_100g", y="nutrition-score-uk_100g", order=2, ci=None, data=food_df, line_kws={'color':'red'})

# Plot residuals from the prediction
sns.residplot(x="fat_100g", y="nutrition-score-uk_100g", order=2, data=food_df, scatter_kws={"s": 80});

"""It seems that the data points are slighly more dispersed when compared to our analysis using `linear regression`!"""

# Save a copy of the original dataframe
food_plain_df = food_df

"""## Feature Engineering
In this section let's quickly focus on **feature engineering** and see if we can further prepare our data for our machine learning algorithms, focusing on performance imporvement.

Let's start by performing a one hot encoding of the ingredients in order to better format the data for our future machine learning algorithms.
"""

# Perform one hot encoding of ingridients
from sklearn.preprocessing import LabelEncoder
import re
from collections import Counter

le = LabelEncoder()
all_ingredients = []

def ingredients_text_to_list(ingredients_text):
  without_parens = re.sub(r"\([^()]*\)", "", ingredients_text.lower())
  without_punc = re.sub("[^A-Za-z0-9,]+", " ", without_parens)
  ingredients_list = without_punc.split(',')
  ingredients_list = [s.strip() for s in ingredients_list]
  all_ingredients.extend(ingredients_list)
  return ingredients_list
  
def removeInsignificantElements(ingredients_list, significance):
    counted = Counter(ingredients_list)
    return [s for s in ingredients_list if (counted[s] >= significance and s and all(x.isalpha() or x.isspace() for x in s))]

def update_ingredients_list(ingredients_list):
  return [s for s in ingredients_list if s in all_ingredients]


food_df["ingredients_list"] = food_df["ingredients_text"].apply(ingredients_text_to_list)

# don't consider ingredients that appear less than 10 times
all_ingredients = removeInsignificantElements(all_ingredients, 10)

food_df["ingredients_list"] = food_df["ingredients_list"].apply(update_ingredients_list)

le.fit(all_ingredients)

for ingredient in le.classes_:
  food_df[ingredient] = 0

for index, row in food_df.iterrows():
  for ingredient in row["ingredients_list"]:
    food_df[ingredient][index] = 1

food_df = food_df.drop(['ingredients_text', 'ingredients_list'], axis=1)
food_df.head(15)

# Synthesize indicator variable that equals to 1 if the nutritient score is above average, 0 otherwise
pd.options.mode.chained_assignment = None
food_df['nutrition_above_avg'] = food_df['nutrition-score-uk_100g'].apply(lambda x : 1 if x > food_df['nutrition-score-uk_100g'].mean() else 0)
food_df.head(15)

# Check data types of the columns
food_df.dtypes

"""## Modeling

### Structure Train & Test Datasets - Nutrition Score Classification

Let's first use `nutrition_above_avg` as our response variable and conduct classification. We will utilize Sklearn's built-in packages to split the training and test sets.
"""

# Use sklearn to split data into train and test sets
from sklearn.model_selection import train_test_split

features = food_df.drop(columns=['product_name', 'countries_en', 'image_url', 'nutrition-score-uk_100g', 'nutrition_above_avg'])
labels = food_df[['nutrition_above_avg']]

print(features.head(5))
print(labels.head(5))

x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.20, random_state=42)

"""### Principal Component Analysis

To ensure that multicollinearity is not affecting our prediction and to reduce the number of features to speed things up, we first conduct a PCA analysis to extract out the most important features.
"""

# PCA analysis on useful predictors
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

scaler = StandardScaler()
scaler.fit(x_train)
x_train_scaled = scaler.transform(x_train)
x_test_scaled = scaler.transform(x_test)
max = 208

thres = []
for i in range(1, max + 1):
  thres.append(i)

explained_ratio = []
explained = []
for i in range(1, max + 1):
  ratio = 0
  pca = PCA(n_components=i)
  pca.fit(x_train_scaled)
  var = pca.explained_variance_ratio_
  for x in var:
    ratio += x
  explained.append(ratio)
  if i == max:
    explained_ratio = var

plt.xlabel('Number of Components')
plt.ylabel('Explained Variance Ratio')
plt.plot(thres, explained)
print("Top 175 variables explain", round(explained[174] * 100, 2), "% of the total variance")

"""It appears that there is not a clear threshold after which the explained variance ratio stops to grow with the increases in the number of components. Let's print out the explained variance array to examine this issue closely."""

# Explained variance ratio
print(explained_ratio)

"""It appears that there is not a set of variables that can explain the bulk of the variance. The best variable can only explain around 3.67% of the label variance. Therefore, we will select a larger amount of fetures to ensure the accuracy of our prediction. 150 seems to be a good choice as the top 175 variables can cover approximately 97.5% of the total variance."""

# Select 175 components according to the Elbow Rule
pca = PCA(n_components=175)
pca.fit(x_train_scaled)
x_test = pca.transform(x_test_scaled)
x_train = pca.transform(x_train_scaled)

"""Let's visualize the distribution of the data points with the top 2 components."""

# Visualize 2 components of PCA
x_train_pca = x_train_scaled
pca_plot = PCA(n_components=2)
comp = pca_plot.fit_transform(x_train_pca)
data = np.transpose(np.array(comp))
plt.scatter(data[0][0:5000], data[1][0:5000])

"""### Decision Tree Model

We start by trying out a decision tree model based on Naive Bayes Classifier.
"""

# Naive Bayes Classifier
from sklearn.naive_bayes import GaussianNB

clf = GaussianNB()
clf.fit(x_train, y_train.values.ravel())
accuracy = clf.score(x_train, y_train.values.ravel())
print("Accuracy on trainig set:", round(accuracy * 100, 2), "%")

accuracy = clf.score(x_test, y_test.values.ravel())
print("Accuracy on test set:", round(accuracy * 100, 2), "%")

"""Although there the model is not overfitting, the 57.81% accuracy on the test set suggests that the performance is quite mediocre - can we do better with other classfication algorithms?

### Logistic Regression Model

Let's try using logistic regression to build the classifier.
"""

# Logistic Regression classifier
clf = LogisticRegression(max_iter=10000)
clf.fit(x_train, y_train.values.ravel())
prediction = clf.predict(x_train)
accuracy = sklearn.metrics.accuracy_score(prediction, y_train)
print("Accuracy on trainig set:", round(accuracy*100, 2), "%")

prediction = clf.predict(x_test)
accuracy = sklearn.metrics.accuracy_score(prediction, y_test)
print("Accuracy on test set:", round(accuracy*100, 2), "%")

"""Great! We reached an accuracy of 91.69% on the test set, and it seems the gap between the accuracies on the training and test sets are not that significant, which means we are not overfitting. Now we have a good model for classification, let's get back to the original `nutrition_above_avg` variable and see if we can accurately predict it using regression.

### Structure Train & Test Datasets - Nutrition Score Regression

Now, let's conduct regression on the `nutrition-score-uk_100g` variable to get a more precise predictive model. We will still conduct a PCA on the dataset and retain 175 variables since the feature set is the same as that for the previous classification model.
"""

# Use sklearn to split data into train and test sets
features = food_df.drop(columns=['product_name', 'countries_en', 'image_url', 'nutrition-score-uk_100g', 'nutrition_above_avg'])
labels = food_df[['nutrition-score-uk_100g']]

x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.20, random_state=42)

scaler = StandardScaler()
scaler.fit(x_train)
x_train_scaled = scaler.transform(x_train)
x_test_scaled = scaler.transform(x_test)

pca = PCA(n_components=175)
pca.fit(x_train_scaled)
x_test = pca.transform(x_test_scaled)
x_train = pca.transform(x_train_scaled)

"""### Linear Regression Models

Let's start with the linear regression model without any regularization.
"""

# Train linear regression model without regularization
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

reg = LinearRegression().fit(x_train, y_train)
print("R-squared value on training set is:", round(reg.score(x_train, y_train)*100, 2), "%")
y_predict_train = reg.predict(x_train)
rmse_train = pow(mean_squared_error(y_train, y_predict_train), 0.5)
print("RMSE on training set is:", round(rmse_train, 2))

print("R-squared value on test set is:", round(reg.score(x_test, y_test)*100, 2), "%")
y_predict_test = reg.predict(x_test)
rmse_test = pow(mean_squared_error(y_test, y_predict_test), 0.5)
print("RMSE on test set is:", round(rmse_test, 2))

"""The results are ok - we have achieved an R-squared value of 74.02% on the test set, and there is clearly no signs of overfitting.

Now, let's try adding in some degree of regularization to see if we can do even better. We will use Ridge regularization here to deal with heavier weights:
"""

# Linear regression model with Ridge regularization
from sklearn.linear_model import Ridge
from sklearn.metrics import r2_score

regr = Ridge(random_state=0)
regr.fit(x_train, y_train)

y_predict_train = regr.predict(x_train)
print("R-squared value on training set is:", round(r2_score(y_predict_train, y_train)*100, 2), "%")
rmse_train = pow(mean_squared_error(y_train, y_predict_train), 0.5)
print("RMSE on training set is:", round(rmse_train, 2))

y_predict_test = regr.predict(x_test)
print("R-squared value on test set is:", round(r2_score(y_predict_test, y_test)*100, 2), "%")
rmse_test = pow(mean_squared_error(y_test, y_predict_test), 0.5)
print("RMSE on test set is:", round(rmse_test, 2))

"""Hmm...it seems the result after regularization isn't that good. We actually arrived at lower R-sqaured scores despite similar RMSE values. Therefore, we will stick to using the OLS linear regression model for now. Let's see if we can do better with more complex models.

### Random Forest Regression Model

Let's also try using a Random Forest Regressor to see if this gives us a better model for regression analysis. To find the best set of hyperparameters, we will first use a grid search to find out a good starting point for `max_depth`and `n_estimators`
"""

# Search for the optimal hyperparameters
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV

regr = RandomForestRegressor()
depth = [5, 10, 20, 30]
estimator = [16, 32, 64, 128]
rf_cv = GridSearchCV(regr, {'max_depth': depth, 'n_estimators': estimator})

rf_cv.fit(x_train, y_train.values.ravel())
rf_cv.best_params_

"""Now we have the best set of hyperparameters, let's dive into the actual regression to see its performance."""

# Use the model with the best set of parameters to build the random forest
y_predict_train = rf_cv.predict(x_train)
print("R-squared value on training set is:", round(r2_score(y_predict_train, y_train)*100, 2), "%")
rmse_train = pow(mean_squared_error(y_train, y_predict_train), 0.5)
print("RMSE on training set is:", round(rmse_train, 2))

y_predict_test = rf_cv.predict(x_test)
print("R-squared value on test set is:", round(r2_score(y_predict_test, y_test)*100, 2), "%")
rmse_test = pow(mean_squared_error(y_test, y_predict_test), 0.5)
print("RMSE on test set is:", round(rmse_test, 2))

"""The R-square value of the prediction on the training set is significantly better than the previous regression models, but there exists a major gap between the R-squared values of the predictions on the training and test sets, which indicates that the model is overfitting. Let's try some degree of regularization to see if the problem goes away."""

# Tune hyperparameters to avoid overfit
regr = RandomForestRegressor(max_depth = 5, n_estimators = 16)
regr.fit(x_train, y_train.values.ravel())
y_predict_train = regr.predict(x_train)
print("R-squared value on training set is:", round(r2_score(y_predict_train, y_train)*100, 2), "%")
rmse_train = pow(mean_squared_error(y_train, y_predict_train), 0.5)
print("RMSE on training set is:", round(rmse_train, 2))

y_predict_test = regr.predict(x_test)
print("R-squared value on test set is:", round(r2_score(y_predict_test, y_test)*100, 2), "%")
rmse_test = pow(mean_squared_error(y_test, y_predict_test), 0.5)
print("RMSE on test set is:", round(rmse_test, 2))

"""We see that even when we prune the trees in the random forest and limit the number of trees, the gap between the R-squared values of predictions on the training and test sets still exist. This indicates that random forest regressor is probably not a good model for conducting regression on our dataset.

### Computer Vision

In this section, we will attempt to train a model to classify foods as "Very Healthy," "Moderately Healthy," "Moderately Unhealthy," or "Very Unhealthy" from their images.

First, let's classify each food's nutrition level in the dataframe:
"""

pd.set_option('display.max_colwidth', None)
food_img_df = food_df[["product_name", "image_url", "nutrition-score-uk_100g"]]

def classify_nutrition(nutrition_score):
  if (nutrition_score <= food_img_df[["nutrition-score-uk_100g"]].quantile(0.25)["nutrition-score-uk_100g"]):
    return "Very Healthy"
  elif (nutrition_score <= food_img_df[["nutrition-score-uk_100g"]].quantile(0.50)["nutrition-score-uk_100g"]):
    return "Moderately Healthy"
  elif (nutrition_score <= food_img_df[["nutrition-score-uk_100g"]].quantile(0.75)["nutrition-score-uk_100g"]):
    return "Moderately Unhealthy"
  return "Very Unhealthy"
  
food_img_df["nutrition-class"] = food_img_df["nutrition-score-uk_100g"].apply(classify_nutrition)

food_img_df.head(5)

"""We split up our dataframe into train, validation, and test data:"""

from sklearn.model_selection import train_test_split

food_img_train_df, food_img_test_df = train_test_split(food_img_df, test_size=0.2)
food_img_train_df, food_img_val_df = train_test_split(food_img_train_df, test_size=0.125)

"""Next, we download the food images into the appropriate folders for classification. This may take a little while."""

import os
import requests
import re

def download_images(row):
   global imgCount, rootFolder, numImgs

   filename = os.path.join(rootFolder, row["nutrition-class"], re.sub(r'[^a-zA-Z0-9]', '', str(row.product_name)) + ".jpg")

   os.makedirs(os.path.dirname(filename), exist_ok=True)

   url = row.image_url
   print(f"Downloading {url} to {filename}")
   r = requests.get(url, allow_redirects=True)
   with open(filename, 'wb') as f:
       f.write(r.content)
       imgCount = imgCount + 1
       print(str(imgCount/numImgs * 100) + "%")

imgCount = 0
rootFolder = "/content/train/"
numImgs = len(food_img_train_df)
food_img_train_df.apply(download_images, axis=1)

imgCount = 0
rootFolder = "/content/test/"
numImgs = len(food_img_test_df)
food_img_test_df.apply(download_images, axis=1)

imgCount = 0
rootFolder = "/content/val/"
numImgs = len(food_img_val_df)
food_img_val_df.apply(download_images, axis=1)

import os
import shutil

train_path="/content/train"
test_path="/content/test"
val_path="/content/val"

print(os.listdir(train_path))
print(os.listdir(test_path))
print(os.listdir(val_path))

"""**We have successfully downloaded our images, let's get to the fun stuff!**

Importing the required packages:
"""

from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt

"""We compute numpy arrays for the images in the training, test, and validation sets:"""

x_train=[]

for folder in os.listdir(train_path):
    sub_path=train_path+"/"+folder
    for img in os.listdir(sub_path):
        image_path=sub_path+"/"+img
        img_arr=cv2.imread(image_path)
        img_arr=cv2.resize(img_arr,(224,224))
        x_train.append(img_arr)

x_test=[]

for folder in os.listdir(test_path):
    sub_path=test_path+"/"+folder
    for img in os.listdir(sub_path):
        image_path=sub_path+"/"+img
        img_arr=cv2.imread(image_path)
        img_arr=cv2.resize(img_arr,(224,224))
        x_test.append(img_arr)


x_val=[]

for folder in os.listdir(val_path):
    sub_path=val_path+"/"+folder
    for img in os.listdir(sub_path):
        image_path=sub_path+"/"+img
        img_arr=cv2.imread(image_path)
        img_arr=cv2.resize(img_arr,(224,224))
        x_val.append(img_arr)

"""Transforming the range of image pixels from [0, 255] to [0, 1]:"""

train_x=np.array(x_train)
test_x=np.array(x_test)
val_x=np.array(x_val)

train_x=train_x/255.0
test_x=test_x/255.0
val_x=val_x/255.0

train_datagen = ImageDataGenerator(rescale = 1./255)
test_datagen = ImageDataGenerator(rescale = 1./255)
val_datagen = ImageDataGenerator(rescale = 1./255)

training_set = train_datagen.flow_from_directory(train_path,
                                                 target_size = (224, 224),
                                                 batch_size = 32,
                                                 class_mode = 'sparse')
test_set = test_datagen.flow_from_directory(test_path,
                                            target_size = (224, 224),
                                            batch_size = 32,
                                            class_mode = 'sparse')
val_set = val_datagen.flow_from_directory(val_path,
                                            target_size = (224, 224),
                                            batch_size = 32,
                                            class_mode = 'sparse')

train_y=training_set.classes
test_y=test_set.classes
val_y=val_set.classes

training_set.class_indices

"""We will use the VGG-19 pre-trained model:"""

IMAGE_SIZE = [224, 224]
vgg = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)

for layer in vgg.layers:
    layer.trainable = False

"""We make sure the output size of our model is 4 (the number of classes we are classifying):"""

x = Flatten()(vgg.output)
prediction = Dense(4, activation='softmax')(x)

model = Model(inputs=vgg.input, outputs=prediction)

model.summary()

model.compile(
  loss='sparse_categorical_crossentropy',
  optimizer="adam",
  metrics=['accuracy']
)

"""In order to reduce overfitting, we want to stop training our model when our validation loss increases in two epochs:"""

from tensorflow.keras.callbacks import EarlyStopping
early_stop = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=2)

"""Let's get to training!"""

history = model.fit(
  train_x,
  train_y,
  validation_data=(val_x, val_y),
  epochs=10,
  callbacks=[early_stop],
  batch_size=32, shuffle=True)

plt.plot(history.history['accuracy'])
plt.title("Training Accuracy vs. Epoch")
plt.xlabel("Epoch")
plt.ylabel("Training Accuracy")
plt.show()

"""In this plot, we can see the training accuracy of our model increase significantly over 4 epochs."""

plt.plot(history.history['loss'])
plt.title("Training Loss vs. Epoch")
plt.xlabel("Epoch")
plt.ylabel("Training Loss")
plt.show()

"""And this plot shows the training loss of our model decrease significantly over 4 epochs.

Finally, let's evaluate our model on the test set!
"""

model.evaluate(test_x, test_y, batch_size=32)

"""**Our model had a final accuracy of 43.45% on the test set.**

While this is not very high, it is clear our model has some success (we expect only a 25% accuracy if we randomly guessed the classification for each food based off its image).

On top of this, the task at hand for the model is very difficult. There are not many (if any) clear features of food images that give away whether the food is very healthy, moderately healthy, moderately unhealthy, or very unhealthy.

### Pipeline Regression Analysis - Energy Score

Lastly, we will construct a pipeline to conduct linear regression for the `energy_100g` of all types of food
"""

# Use sklearn to split data into train and test sets
features = food_df.drop(columns=['product_name', 'countries_en', 'image_url', 'energy_100g', 'nutrition-score-uk_100g', 'nutrition_above_avg'])
labels = food_df[['energy_100g']]

print(features.head(5))
print(labels.head(5))

x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.20, random_state=42)

"""Now, let's construct a pipeline that includes variable sclaing, PCA, and linear regression to help us automate the regression."""

# Using a pipeline to conduct linear regression
scl = StandardScaler()
pca = PCA()
clf = LinearRegression()
pipe = Pipeline(steps=[('Scale', scl), ('PCA', pca), ('LinReg', clf)])
pipe.fit(x_train, y_train.values.ravel())

prediction = pipe.predict(x_train)
accuracy = sklearn.metrics.r2_score(prediction, y_train)
print("R-squared value on training set is:", round(accuracy*100, 2), "%")
rmse_train = pow(mean_squared_error(prediction, y_train), 0.5)
print("RMSE on training set is:", round(rmse_train, 2))

prediction = pipe.predict(x_test)
accuracy = sklearn.metrics.r2_score(prediction, y_test)
print("R-squared value on test set is:", round(accuracy*100, 2), "%")
rmse_test = pow(mean_squared_error(prediction, y_test), 0.5)
print("RMSE on test set is:", round(rmse_test, 2))

"""Great! We achieved a 96.39% R-squared value on the test set, and overfit doesn't seem to be an issue.

As of now, we have constructed 2 accurate regression models for predicting the nutrition score and energy associated with different types of food, based on their ingredients.

Thank you for taking the journey with us!

## Description of Challenges and Obstacles Faced

Originally, we planned on predicting the carbon footprint of foods in addition to the nutrition score of foods. However, we soon realized the dataset did not have nearly enough observations with carbon footprint data and had to scrap this element from our project.

In the classification and regression parts of the project, we run into the challenge of overfitting and ineffective regularization. For the random forest regressor, although the R-squared value on the training set is really high, there exists a large gap between the R-squared values of the train and test set. We had to manually reduce the number of estimators and the max depth of trees to regularize our model. For the regularized linear regression part, we started with ElasticNet, but it turned out to have very poor performance. So we tested using Lasso and Ridge regression separately to identify the issue. Through testing, we realized that Lasso regression has a poor performance, so we decided to go with the single Ridge regression.

We ran into multiple obstacles with the computer vision aspect of this project. First, we had technical difficulty getting the MXNet framework to work properly and had to switch to TensorFlow. Additionally, we faced problems with overfitting. Originally, the model had a 100% accuracy on the training data, but around a 38% accuracy on the test set. In order to address this, we added a validation set and stopped training our model when validation loss increased twice. This reduced the overfitting and improved our test accuracy to 43.45%.

## Potential Next Steps and Future Direction

There can definitely be improvements in how we first initially remove sparsely populated columns from our raw dataset. Instead of just relying on intuition to determine which columns to keep, perhaps we can algorithmically decide which columns to keep by mathematically determining how many non-null values the column has.

We are also thinking of expanding our dataset by joining the current food nutrition dataset with other food-related datasets. By doing so, we will be able to explore variables that can serve as better predictors of food nutrition scores and energy levels. Also, if we can create a large aggregation of food data, we will be able to run neural networks and deep learning models to evaluate nutrition scores and energy levels more accurately.

There is also plenty of room to improve our computer vision section. First, we can better scale up our process for retrieving images. Speeding this up is essential if we increase our image set. Additionally, although we were able to reduce overfitting in our computer vision model, it is still present. In the future, we should attempt to reduce this further by getting a better training set. We can do this by merging our current dataset with one that has better/multiple images for the foods. We can also use transformations, such as rotation and reflection, to manually augment our training set to help reduce overfitting.

Besides all the current models and objectives, we are also considering developing a recommendation system for people from different nationalities with different nutritional needs and providing a picture of the image. We can explore the popularity of food in each country and make recommendations according to their nutrition score and energy level. Then, we scan through our database of images and select the ones that match the preferences of our customers as the final output.
"""